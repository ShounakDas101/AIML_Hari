{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShounakDas101/AIML_Hari/blob/main/TopGunGATHari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2bhD2R7moni",
        "outputId": "43bf4a11-ae0b-4a3f-ef9f-39b1500d1f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WMKUxKbmlqa",
        "outputId": "d503fd49-aff6-4dc0-f638-a6034ed326fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['X_jet', 'm', 'iphi', 'pt', 'ieta']\n",
            "0       291.988312\n",
            "1       466.154877\n",
            "2       451.912231\n",
            "3       393.327454\n",
            "4       180.342300\n",
            "           ...    \n",
            "2043    231.916153\n",
            "2044    239.267395\n",
            "2045    412.135864\n",
            "2046    123.064384\n",
            "2047    231.667877\n",
            "Name: m, Length: 2048, dtype: float64 0       33.0\n",
            "1       48.0\n",
            "2        0.0\n",
            "3       40.0\n",
            "4       19.0\n",
            "        ... \n",
            "2043    60.0\n",
            "2044    57.0\n",
            "2045    14.0\n",
            "2046    66.0\n",
            "2047     0.0\n",
            "Name: iphi, Length: 2048, dtype: float64 0       962.311523\n",
            "1       555.076416\n",
            "2       434.385803\n",
            "3       418.650391\n",
            "4       985.945129\n",
            "           ...    \n",
            "2043    860.787903\n",
            "2044    946.670593\n",
            "2045    975.661499\n",
            "2046    610.374329\n",
            "2047    474.445892\n",
            "Name: pt, Length: 2048, dtype: float64 0       16.0\n",
            "1       36.0\n",
            "2       19.0\n",
            "3       21.0\n",
            "4       16.0\n",
            "        ... \n",
            "2043    42.0\n",
            "2044    20.0\n",
            "2045    42.0\n",
            "2046    38.0\n",
            "2047    25.0\n",
            "Name: ieta, Length: 2048, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pyarrow.parquet as pq\n",
        "\n",
        "topgun_file ='/content/drive/MyDrive/data/raw/output_2048_lines.parquet'\n",
        "# Read the Parquet file into a PyArrow Table\n",
        "parquet_table = pq.read_table(topgun_file)\n",
        "# Convert the PyArrow Table to a pandas DataFrame\n",
        "data_frame = parquet_table.to_pandas()\n",
        "# Get the keys (column names) of the DataFrame\n",
        "keys = data_frame.columns.tolist()  # Convert the column names to a list\n",
        "print(keys)\n",
        "# data_frame['m']\n",
        "print(data_frame['m'],data_frame['iphi'],data_frame['pt'],data_frame['ieta'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "QqADiiuAIjjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43ba476-cb69-4d90-8a14-d94538ce61b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prcy8ud8mlqc",
        "outputId": "95b8e433-2c89-4d01-9cc1-c2e1390dd525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Gr4XDlmlqd"
      },
      "outputs": [],
      "source": [
        "import torch_geometric\n",
        "import numpy as np\n",
        "from torch_geometric.utils import get_laplacian, to_scipy_sparse_matrix, to_dense_adj, to_undirected\n",
        "\n",
        "\n",
        "def eigvec_normalizer(EigVecs, EigVals, normalization=\"L2\", eps=1e-12):\n",
        "    \"\"\"\n",
        "    Implement different eigenvector normalizations.\n",
        "    \"\"\"\n",
        "\n",
        "    EigVals = EigVals.unsqueeze(0)\n",
        "\n",
        "    if normalization == \"L1\":\n",
        "        # L1 normalization: eigvec / sum(abs(eigvec))\n",
        "        denom = EigVecs.norm(p=1, dim=0, keepdim=True)\n",
        "\n",
        "    elif normalization == \"L2\":\n",
        "        # L2 normalization: eigvec / sqrt(sum(eigvec^2))\n",
        "        denom = EigVecs.norm(p=2, dim=0, keepdim=True)\n",
        "\n",
        "    elif normalization == \"abs-max\":\n",
        "        # AbsMax normalization: eigvec / max|eigvec|\n",
        "        denom = torch.max(EigVecs.abs(), dim=0, keepdim=True).values\n",
        "\n",
        "    elif normalization == \"wavelength\":\n",
        "        # AbsMax normalization, followed by wavelength multiplication:\n",
        "        # eigvec * pi / (2 * max|eigvec| * sqrt(eigval))\n",
        "        denom = torch.max(EigVecs.abs(), dim=0, keepdim=True).values\n",
        "        eigval_denom = torch.sqrt(EigVals)\n",
        "        eigval_denom[EigVals < eps] = 1  # Problem with eigval = 0\n",
        "        denom = denom * eigval_denom * 2 / np.pi\n",
        "\n",
        "    elif normalization == \"wavelength-asin\":\n",
        "        # AbsMax normalization, followed by arcsin and wavelength multiplication:\n",
        "        # arcsin(eigvec / max|eigvec|)  /  sqrt(eigval)\n",
        "        denom_temp = torch.max(EigVecs.abs(), dim=0, keepdim=True).values.clamp_min(eps).expand_as(EigVecs)\n",
        "        EigVecs = torch.asin(EigVecs / denom_temp)\n",
        "        eigval_denom = torch.sqrt(EigVals)\n",
        "        eigval_denom[EigVals < eps] = 1  # Problem with eigval = 0\n",
        "        denom = eigval_denom\n",
        "\n",
        "    elif normalization == \"wavelength-soft\":\n",
        "        # AbsSoftmax normalization, followed by wavelength multiplication:\n",
        "        # eigvec / (softmax|eigvec| * sqrt(eigval))\n",
        "        denom = (F.softmax(EigVecs.abs(), dim=0) * EigVecs.abs()).sum(dim=0, keepdim=True)\n",
        "        eigval_denom = torch.sqrt(EigVals)\n",
        "        eigval_denom[EigVals < eps] = 1  # Problem with eigval = 0\n",
        "        denom = denom * eigval_denom\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported normalization `{normalization}`\")\n",
        "\n",
        "    denom = denom.clamp_min(eps).expand_as(EigVecs)\n",
        "    EigVecs = EigVecs / denom\n",
        "\n",
        "    return EigVecs\n",
        "\n",
        "def get_lap_decomp_stats(evals, evects, max_freqs, eigvec_norm='L2'):\n",
        "\n",
        "    N = len(evals)  # Number of nodes, including disconnected nodes.\n",
        "\n",
        "    # Keep up to the maximum desired number of frequencies.\n",
        "    idx = evals.argsort()[:max_freqs]\n",
        "    evals, evects = evals[idx], np.real(evects[:, idx])\n",
        "    evals = torch.from_numpy(np.real(evals)).clamp_min(0)\n",
        "\n",
        "    # Normalize and pad eigen vectors.\n",
        "    evects = torch.from_numpy(evects).float()\n",
        "    evects = eigvec_normalizer(evects, evals, normalization=eigvec_norm)\n",
        "    if N < max_freqs:\n",
        "        EigVecs = F.pad(evects, (0, max_freqs - N), value=float('nan'))\n",
        "    else:\n",
        "        EigVecs = evects\n",
        "\n",
        "    # Pad and save eigenvalues.\n",
        "    if N < max_freqs:\n",
        "        EigVals = F.pad(evals, (0, max_freqs - N), value=float('nan')).unsqueeze(0)\n",
        "    else:\n",
        "        EigVals = evals.unsqueeze(0)\n",
        "    EigVals = EigVals.repeat(N, 1).unsqueeze(2)\n",
        "\n",
        "    return EigVals, EigVecs\n",
        "\n",
        "def compute_enc_transform(x, edge_index, transform_flags):\n",
        "\n",
        "    N = x.shape[0]\n",
        "\n",
        "    to_return = {}\n",
        "\n",
        "    if transform_flags[\"LapPE\"]:\n",
        "        undir_edge_idx = to_undirected(edge_index, num_nodes  = N)\n",
        "        L = to_scipy_sparse_matrix(\n",
        "            *get_laplacian(undir_edge_idx, normalization=transform_flags[\"LapPEnorm\"], num_nodes=N)\n",
        "        )\n",
        "        evals, evects = np.linalg.eigh(L.toarray())\n",
        "        max_freqs = transform_flags[\"LapPEmax_freq\"]\n",
        "        eigvec_norm = transform_flags[\"LapPEeig_norm\"]\n",
        "\n",
        "        EigVals, EigVecs = get_lap_decomp_stats(\n",
        "            evals=evals, evects=evects,\n",
        "            max_freqs=max_freqs,\n",
        "            eigvec_norm=eigvec_norm\n",
        "        )\n",
        "\n",
        "        to_return['eigvals'] = EigVals\n",
        "        to_return['eigvecs'] = EigVecs\n",
        "    return to_return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKy69HDMmlqe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ded201fd-12e7-4c62-f218-27ed7ff01d5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef positional_encoding(data, pe_scales):\\n    pe_cos = torch.cat([torch.cos(2**i * np.pi * torch.as_tensor(data))\\n                       for i in range(pe_scales)], dim=1)\\n    pe_sin = torch.cat([torch.sin(2**i * np.pi * torch.as_tensor(data))\\n                       for i in range(pe_scales)], dim=1)\\n\\n    output= torch.cat([torch.as_tensor(data), pe_cos, pe_sin], dim=1)\\n    return output\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "'''\n",
        "def positional_encoding(data, pe_scales):\n",
        "    pe_cos = torch.cat([torch.cos(2**i * np.pi * torch.as_tensor(data))\n",
        "                       for i in range(pe_scales)], dim=1)\n",
        "    pe_sin = torch.cat([torch.sin(2**i * np.pi * torch.as_tensor(data))\n",
        "                       for i in range(pe_scales)], dim=1)\n",
        "\n",
        "    output= torch.cat([torch.as_tensor(data), pe_cos, pe_sin], dim=1)\n",
        "    return output\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cMti47Vmlqf"
      },
      "outputs": [],
      "source": [
        "m0_scale=85\n",
        "m1_scale=415"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_D1_TLemlqf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "def points_all_channels(X_jets, suppression_thresh):\n",
        "    idx = np.where(abs(X_jets).sum(axis=0) > suppression_thresh)\n",
        "    pos = np.array(idx).T / X_jets.shape[1]\n",
        "    x = X_jets[:, idx[0], idx[1]].T\n",
        "\n",
        "    return x, pos\n",
        "\n",
        "class PointCloudFromParquetDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,data_dir,save_data,id,filename,\n",
        "                    transform_flags,suppresion_thresh,k,min_mass,max_mass,num_bins):\n",
        "        super().__init__()\n",
        "\n",
        "        self.id = id\n",
        "        self.file = pq.ParquetFile(filename)\n",
        "        self.root_dir = data_dir\n",
        "        self.save_data = save_data\n",
        "        self.transform_flags = transform_flags\n",
        "        self.suppression_thresh = suppresion_thresh\n",
        "        self.k = k\n",
        "        self.min_mass=min_mass\n",
        "        self.max_mass=max_mass\n",
        "        self.num_bins=num_bins\n",
        "\n",
        "        bin_size=(max_mass-min_mass)/num_bins\n",
        "        self.bins=[min_mass + i*bin_size for i in range(num_bins)]\n",
        "\n",
        "    def __getitem__(self, idx, ):\n",
        "        row = self.file.read_row_group(idx).to_pydict()\n",
        "        arr = np.array(row['X_jet'][0])\n",
        "        x, pos = points_all_channels(arr, self.suppression_thresh)\n",
        "        pt = row['pt'][0]\n",
        "        ieta = row['ieta'][0]\n",
        "        iphi = row['iphi'][0]\n",
        "        m = row['m'][0]\n",
        "        m=m-m0_scale\n",
        "        m=m/m1_scale\n",
        "        m_class= (-1)\n",
        "        for it,bin_start in enumerate(self.bins):\n",
        "            if bin_start > m:\n",
        "                m_class= it -1\n",
        "                break\n",
        "        if m_class == -1:\n",
        "            m_class=self.num_bins -1\n",
        "        y_class=m_class\n",
        "        x = np.concatenate([x, pos], axis=1)\n",
        "        pos = torch.as_tensor(pos, dtype=torch.float)\n",
        "        x = torch.as_tensor(x)\n",
        "        edge_index = torch_geometric.nn.knn_graph(x=pos, k = self.k, num_workers=0)\n",
        "        transforms = compute_enc_transform(x, edge_index, self.transform_flags)\n",
        "        x = torch.cat([x, transforms['eigvecs'], transforms['eigvals'].squeeze(-1)], dim=-1)\n",
        "        data = torch_geometric.data.Data(\n",
        "            pos=pos.float(),x=x.float(),\n",
        "            pt=torch.as_tensor(pt).unsqueeze(-1),\n",
        "            ieta=torch.as_tensor(ieta).unsqueeze(-1),\n",
        "            iphi=torch.as_tensor(iphi).unsqueeze(-1),\n",
        "            y=torch.as_tensor(m),\n",
        "            y_class=y_class\n",
        "        )\n",
        "        if self.save_data:\n",
        "            torch.save(data, os.path.join(self.save_data, f'{self.id}_{idx}.pt'))\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.file.num_row_groups\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3yVoEZbmlqg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "class TopGunPreprocessor():\n",
        "    def __init__(self,data_dir,num_files,test_ratio,val_ratio,transform_flags,min_threshold,k,min_mass=0,max_mass=40,num_bins=4):\n",
        "        self.data_dir=data_dir\n",
        "        self.num_files=num_files\n",
        "        self.test_ratio=test_ratio\n",
        "        self.val_ratio=val_ratio\n",
        "        self.transform_flags=transform_flags\n",
        "        self.min_threshold=min_threshold\n",
        "        self.k=k\n",
        "        self.min_mass=min_mass\n",
        "        self.max_mass=max_mass\n",
        "        self.num_bins=num_bins\n",
        "        self.preprocess()\n",
        "\n",
        "    def preprocess(self):\n",
        "        paths = list(glob.glob(os.path.join(self.data_dir, \"raw\", \"*.parquet\")))\n",
        "\n",
        "        dsets = []\n",
        "        for it,path in enumerate(tqdm(paths[0:self.num_files])):\n",
        "            dsets.append(\n",
        "                PointCloudFromParquetDataset(\n",
        "                    data_dir = self.data_dir,\n",
        "                    save_data = os.path.join(self.data_dir, \"saved\"),\n",
        "                    id = it,\n",
        "                    filename = path,\n",
        "                    transform_flags = self.transform_flags,\n",
        "                    suppresion_thresh=self.min_threshold,\n",
        "                    k = self.k,min_mass=self.min_mass,max_mass=self.max_mass,num_bins=self.num_bins\n",
        "                )\n",
        "            )\n",
        "\n",
        "        combined_dset = torch.utils.data.ConcatDataset(dsets)\n",
        "\n",
        "        sampled_data_size = int(len(combined_dset) * 0.005)\n",
        "\n",
        "        random_indices = random.sample(range(len(combined_dset)), sampled_data_size)\n",
        "\n",
        "        combined_dset = torch.utils.data.Subset(combined_dset, random_indices)\n",
        "\n",
        "        val_size = int(len(combined_dset) * self.val_ratio)\n",
        "        test_size = int(len(combined_dset) * self.test_ratio)\n",
        "        train_size = len(combined_dset) - val_size - test_size\n",
        "\n",
        "        train_dset, val_dset, test_dset = torch.utils.data.random_split(\n",
        "            combined_dset,\n",
        "            [train_size, val_size, test_size],\n",
        "            generator=torch.Generator().manual_seed(42),\n",
        "        )\n",
        "\n",
        "        self.train_dataset = train_dset\n",
        "        self.val_dataset = val_dset\n",
        "        self.test_dataset = test_dset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6syAmJEhmlqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c8cd2bf66b4348f9b4646b24ef2cb5a9",
            "a8c55b8c5bac41228a5786b323c48691",
            "28b946be94f74e1f928de2caa4d0711c",
            "5cccd86c4af84044a82fe2293ec7b19c",
            "5a21ad99f688433eb4d3abcd344ed6b2",
            "24dba89fb6ff4e79bed81b14e78e2f1d",
            "92990433ccd94541b5f455a35a2de8db",
            "03c9fc174f04440cb90758d0a87f4db4",
            "4607c425a303422fad287ddf978ee3dd",
            "acb4379ad1aa4542a18bb2f78556f130",
            "1a2d9d7c5ec94bcdbcdcace2b832e1ba"
          ]
        },
        "outputId": "9e7f4129-bf4f-4623-9f56-006f6d0edd80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8cd2bf66b4348f9b4646b24ef2cb5a9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dset = TopGunPreprocessor(data_dir='/content/drive/MyDrive/data/',num_files=3,test_ratio=.2,val_ratio=.2,transform_flags={\"LapPE\": True,\"LapPEnorm\": \"sym\",\"LapPEmax_freq\": 10,\"LapPEeig_norm\": \"L2\",\"RWSE\": False,\"RWSEkernel_times\": [2, 3, 5, 7, 10]},min_threshold=1e-3,k = 20,min_mass=0,max_mass=1,num_bins=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BsJ8Xc6mlqh"
      },
      "outputs": [],
      "source": [
        "train_dataset=dset.train_dataset\n",
        "val_dataset = dset.val_dataset\n",
        "test_dataset = dset.test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dibWecsKmlqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9e1179-7c4f-4b2f-a0cb-885c3174cee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "300\n"
          ]
        }
      ],
      "source": [
        "print(len(test_dataset))\n",
        "print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall torch-cluster -y\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "id": "VanGG-xjofVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch-cluster"
      ],
      "metadata": {
        "id": "G_vpHVAtnn_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk1o-6NFmlqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8ec198-6225-4b5e-e295-064f8f11f952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[869, 30], y=0.9618836045265198, pos=[869, 2], pt=[1], ieta=[1], iphi=[1], y_class=9)\n",
            "Data(x=[893, 30], y=0.2744690179824829, pos=[893, 2], pt=[1], ieta=[1], iphi=[1], y_class=2)\n",
            "Data(x=[685, 30], y=0.8045699596405029, pos=[685, 2], pt=[1], ieta=[1], iphi=[1], y_class=8)\n",
            "Data(x=[1066, 30], y=0.3707379102706909, pos=[1066, 2], pt=[1], ieta=[1], iphi=[1], y_class=3)\n",
            "Data(x=[912, 30], y=0.543761670589447, pos=[912, 2], pt=[1], ieta=[1], iphi=[1], y_class=5)\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(test_dataset[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGN2W_kBmlqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24f8b95-a3e7-47ac-82df-456610ff9020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "loader_type = torch_geometric.data.DataLoader\n",
        "train_loader = loader_type( train_dataset, shuffle=True, batch_size=128, pin_memory=True, num_workers=0,drop_last=True)\n",
        "val_loader = loader_type( val_dataset, shuffle=True, batch_size=128, pin_memory=True, num_workers=0,drop_last=True)\n",
        "test_loader = loader_type( test_dataset, shuffle=True, batch_size=128, pin_memory=True, num_workers=0,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for batch in train_loader:\n",
        "#     print(batch.y_class[1])\n",
        "#     break"
      ],
      "metadata": {
        "id": "EpFzpWOTZGzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgEWkEMHmlqj"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleGAT(nn.Module):\n",
        "    def __init__(self,  x_size, edge_feat='none', k=7, use_pe=False, pe_scales=0):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.edge_feat = edge_feat\n",
        "        # self.args = args\n",
        "        if self.edge_feat == 'none':\n",
        "            edge_dim = None\n",
        "\n",
        "        self.gat_conv_1 = torch_geometric.nn.GATv2Conv(\n",
        "            in_channels=x_size if not use_pe else x_size * (pe_scales * 2 + 1),\n",
        "            out_channels=16,\n",
        "            heads=4,\n",
        "            edge_dim=edge_dim\n",
        "        )\n",
        "        self.bn_1 = torch_geometric.nn.BatchNorm(64)\n",
        "        self.gat_conv_2 = torch_geometric.nn.GATv2Conv(\n",
        "            in_channels=16 * 4,\n",
        "            out_channels=32,\n",
        "            heads=4,\n",
        "            edge_dim=edge_dim\n",
        "        )\n",
        "        self.bn_2 = torch_geometric.nn.BatchNorm(128)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        pos = data.pos\n",
        "        batch = data.batch\n",
        "        x = data.x\n",
        "\n",
        "        edge_index = torch_geometric.nn.knn_graph(x=pos, k=self.k, batch=batch)\n",
        "        if self.edge_feat == 'none':\n",
        "            edge_attr = None\n",
        "\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Edge feat {self.edge_feat} is not implemented\")\n",
        "\n",
        "        x_out = self.act(self.bn_1(self.gat_conv_1(\n",
        "            x, edge_index, edge_attr=edge_attr)))\n",
        "        x_out = self.act(self.bn_2(self.gat_conv_2(\n",
        "            x_out, edge_index, edge_attr=edge_attr)))\n",
        "\n",
        "        x_out = torch_geometric.nn.global_mean_pool(x_out, batch)\n",
        "\n",
        "        return x_out\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Model prints with number of trainable parameters\n",
        "        \"\"\"\n",
        "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        return super().__str__() + '\\nTrainable parameters: {}'.format(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj-JqFSxmlqk"
      },
      "outputs": [],
      "source": [
        "class MLPStack(torch.nn.Module):\n",
        "    def __init__(self, layers, bn=True, act=True, p=0):\n",
        "        super().__init__()\n",
        "        assert len(layers) > 1, \"At least input and output channels must be provided\"\n",
        "\n",
        "        modules = []\n",
        "        for i in range(1, len(layers)):\n",
        "            modules.append(\n",
        "                torch.nn.Linear(layers[i-1], layers[i])\n",
        "            )\n",
        "            modules.append(\n",
        "                torch.nn.BatchNorm1d(layers[i]) if bn == True else torch.nn.Identity()\n",
        "            )\n",
        "            modules.append(\n",
        "                torch.nn.SiLU() if bn == True else torch.nn.Identity()\n",
        "            )\n",
        "            modules.append(\n",
        "                torch.nn.Dropout(p=p) if p != 0 else torch.nn.Identity()\n",
        "            )\n",
        "\n",
        "        self.mlp_stack = torch.nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp_stack(x)\n",
        "\n",
        "class RegressModel(nn.Module):\n",
        "    def __init__(self, model, in_features, predict_bins=True, num_bins=10):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.predict_bins = predict_bins\n",
        "\n",
        "        self.out_mlp = MLPStack(\n",
        "            [in_features + 3, in_features * 2, in_features * 2, in_features, in_features // 2],\n",
        "            bn=True, act=True\n",
        "        )\n",
        "\n",
        "        self.out_regress = torch.nn.Linear(in_features//2, 1)\n",
        "\n",
        "        if self.predict_bins:\n",
        "            self.out_pred = torch.nn.Linear(in_features // 2, num_bins)\n",
        "\n",
        "    def forward(self, data):\n",
        "        return_dict = {}\n",
        "\n",
        "\n",
        "        out = self.model(data)\n",
        "        out = torch.cat(\n",
        "            [out, data.pt.unsqueeze(-1), data.ieta.unsqueeze(-1), data.iphi.unsqueeze(-1)], dim=1\n",
        "        )\n",
        "        out = self.out_mlp(out)\n",
        "        regress_out = self.out_regress(out)\n",
        "\n",
        "        return_dict['regress'] = regress_out\n",
        "\n",
        "        if self.predict_bins:\n",
        "            pred_out = self.out_pred(out)\n",
        "            return_dict['class'] = pred_out\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Model prints with number of trainable parameters\n",
        "        \"\"\"\n",
        "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "        return super().__str__() + '\\nTrainable parameters: {}'.format(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_K6G-Q3mlqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "894bcb2a-255a-4499-f6bc-516ede7fa2aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegressModel(\n",
              "  (model): SimpleGAT(\n",
              "    (gat_conv_1): GATv2Conv(30, 16, heads=4)\n",
              "    (bn_1): BatchNorm(64)\n",
              "    (gat_conv_2): GATv2Conv(64, 32, heads=4)\n",
              "    (bn_2): BatchNorm(128)\n",
              "    (act): ReLU()\n",
              "  )\n",
              "  (out_mlp): MLPStack(\n",
              "    (mlp_stack): Sequential(\n",
              "      (0): Linear(in_features=131, out_features=256, bias=True)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Identity()\n",
              "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): SiLU()\n",
              "      (7): Identity()\n",
              "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (9): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (10): SiLU()\n",
              "      (11): Identity()\n",
              "      (12): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (14): SiLU()\n",
              "      (15): Identity()\n",
              "    )\n",
              "  )\n",
              "  (out_regress): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (out_pred): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "input_size = 30\n",
        "\n",
        "\n",
        "model = SimpleGAT(x_size=input_size)\n",
        "Final_model=RegressModel(model, in_features = 128, predict_bins=True, num_bins=10)\n",
        "Final_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# clearing cuda cache memory\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "p54DfaGnVfOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688f20f6-4b71-4f31-945f-fc64583193f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaJmxYRZmlql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a04b3ef-fa1b-4d09-9959-c88f0a5d27a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 - Training: 100%|██████████| 7/7 [07:56<00:00, 68.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Average Training Loss: 26592.9442\n",
            "train acc 0.109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 - Validation: 100%|██████████| 2/2 [02:20<00:00, 70.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Average Validation Loss: 23896.7461\n",
            "Val acc 0.10546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Training: 100%|██████████| 7/7 [07:46<00:00, 66.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Average Training Loss: 18092.3571\n",
            "train acc 0.10714285714285714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Validation: 100%|██████████| 2/2 [02:21<00:00, 70.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Average Validation Loss: 20494.8975\n",
            "Val acc 0.07421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training: 100%|██████████| 7/7 [07:51<00:00, 67.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Average Training Loss: 15679.7461\n",
            "train acc 0.09598214285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Validation: 100%|██████████| 2/2 [02:17<00:00, 68.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Average Validation Loss: 16795.0654\n",
            "Val acc 0.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training: 100%|██████████| 7/7 [07:51<00:00, 67.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Average Training Loss: 14608.6037\n",
            "train acc 0.109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Validation: 100%|██████████| 2/2 [02:15<00:00, 68.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Average Validation Loss: 18081.6289\n",
            "Val acc 0.078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training: 100%|██████████| 7/7 [07:54<00:00, 67.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Average Training Loss: 14800.3200\n",
            "train acc 0.11049107142857142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Validation: 100%|██████████| 2/2 [02:19<00:00, 69.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Average Validation Loss: 14521.1738\n",
            "Val acc 0.09375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training: 100%|██████████| 7/7 [08:22<00:00, 71.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Average Training Loss: 14180.8595\n",
            "train acc 0.09598214285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Validation: 100%|██████████| 2/2 [02:26<00:00, 73.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Average Validation Loss: 14559.0146\n",
            "Val acc 0.11328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training: 100%|██████████| 7/7 [07:56<00:00, 68.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Average Training Loss: 14184.0759\n",
            "train acc 0.11049107142857142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Validation: 100%|██████████| 2/2 [02:18<00:00, 69.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Average Validation Loss: 13874.2168\n",
            "Val acc 0.12890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Training: 100%|██████████| 7/7 [07:54<00:00, 67.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Average Training Loss: 14233.3624\n",
            "train acc 0.11160714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Validation: 100%|██████████| 2/2 [02:26<00:00, 73.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Average Validation Loss: 15175.3540\n",
            "Val acc 0.109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Training: 100%|██████████| 7/7 [08:05<00:00, 69.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Average Training Loss: 13669.8097\n",
            "train acc 0.12165178571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Validation: 100%|██████████| 2/2 [02:23<00:00, 71.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Average Validation Loss: 14505.8882\n",
            "Val acc 0.1171875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Training: 100%|██████████| 7/7 [07:55<00:00, 67.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Average Training Loss: 13860.7578\n",
            "train acc 0.109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Validation: 100%|██████████| 2/2 [02:14<00:00, 67.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Average Validation Loss: 16307.0664\n",
            "Val acc 0.07421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming Final_model, train_loader, and val_loader are defined\n",
        "lr = 0.001  # Assuming lr is defined\n",
        "\n",
        "criterion = torch.nn.MSELoss().to(device)\n",
        "trainable_params = filter(lambda p: p.requires_grad, Final_model.parameters())\n",
        "optimizer = torch.optim.AdamW(trainable_params, lr=lr)\n",
        "\n",
        "criterion_dict = {}\n",
        "criterion_dict['regress'] = torch.nn.MSELoss()\n",
        "#criterion_dict['class'] = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    # Training\n",
        "    Final_model.train()\n",
        "    tqdm_iter = tqdm(train_loader, total=len(train_loader))\n",
        "    tqdm_iter.set_description(f\"Epoch {epoch} - Training\")\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    for it, batch in enumerate(tqdm_iter):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        m = batch.y\n",
        "        out = Final_model(batch)\n",
        "\n",
        "        loss_dict = {}\n",
        "        loss = 0\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "                #print(\"out\",out['regress'][i],\"batch_yclass\",batch.y_class[i])\n",
        "            if(torch.floor(10*out['regress'][i])==batch.y_class[i]):\n",
        "                true_preds+=1\n",
        "                #print(\"out\",torch.floor(10*out['regress'][i])==batch.y_class[i])\n",
        "            #print(torch.floor(out['regress']*10))\n",
        "        num_preds += len(batch)\n",
        "        m = m * m1_scale + m0_scale\n",
        "        out['regress'] = out['regress'] * m1_scale + m0_scale\n",
        "        loss_dict['regress'] = criterion(out['regress'], m.unsqueeze(-1))\n",
        "        loss += loss_dict['regress']\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Average Training Loss: {average_train_loss:.4f}\")\n",
        "    print(\"train acc\",true_preds/num_preds)\n",
        "    # Validation\n",
        "    Final_model.eval()\n",
        "    val_tqdm_iter = tqdm(val_loader, total=len(val_loader))\n",
        "    val_tqdm_iter.set_description(f\"Epoch {epoch} - Validation\")\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    for it, batch in enumerate(val_tqdm_iter):\n",
        "        with torch.no_grad():\n",
        "            batch = batch.to(device)\n",
        "            m = batch.y\n",
        "            out = Final_model(batch)\n",
        "\n",
        "            loss_dict = {}\n",
        "            loss = 0\n",
        "\n",
        "            for i in range(len(batch)):\n",
        "                #print(\"out\",out['regress'][i],\"batch_yclass\",batch.y_class[i])\n",
        "                if(torch.floor(10*out['regress'][i])==batch.y_class[i]):\n",
        "                    true_preds+=1\n",
        "                #print(\"out\",torch.floor(10*out['regress'][i])==batch.y_class[i])\n",
        "            #print(torch.floor(out['regress']*10))\n",
        "            num_preds += len(batch)\n",
        "\n",
        "\n",
        "            # Scale both target and predicted values before calculating the loss\n",
        "            m = m * m1_scale + m0_scale\n",
        "            out['regress'] = out['regress'] * m1_scale + m0_scale\n",
        "\n",
        "# Calculate the loss on scaled values\n",
        "            loss_dict['regress'] = criterion(out['regress'], m.unsqueeze(-1))\n",
        "            loss += loss_dict['regress']\n",
        "\n",
        "\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch} - Average Validation Loss: {average_val_loss:.4f}\")\n",
        "    print(\"Val acc\",true_preds/num_preds)\n",
        "    # Print or compute validation accuracy if applicable\n",
        "    # Add your validation accuracy computation code here\n",
        "\n",
        "    # Reset the model back to training mode\n",
        "    Final_model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "    Final_model.eval()\n",
        "    val_tqdm_iter = tqdm(val_loader, total=len(val_loader))\n",
        "    val_tqdm_iter.set_description(f\"Epoch {epoch} - Validation\")\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    for it, batch in enumerate(val_tqdm_iter):\n",
        "        with torch.no_grad():\n",
        "            batch = batch.to(device)\n",
        "            m = batch.y\n",
        "            out = Final_model(batch)\n",
        "\n",
        "            loss_dict = {}\n",
        "            loss = 0\n",
        "\n",
        "            for i in range(len(batch)):\n",
        "                print(\"out\",out['regress'][i],\"batch_yclass\",batch.y_class[i])\n",
        "                if(torch.floor(10*out['regress'][i])==batch.y_class[i]):\n",
        "                    true_preds+=1\n",
        "                #print(\"out\",torch.floor(10*out['regress'][i])==batch.y_class[i])\n",
        "            #print(torch.floor(out['regress']*10))\n",
        "            num_preds += len(batch)\n",
        "\n",
        "\n",
        "            # Scale both target and predicted values before calculating the loss\n",
        "            m = m * m1_scale + m0_scale\n",
        "            out['regress'] = out['regress'] * m1_scale + m0_scale\n",
        "\n",
        "# Calculate the loss on scaled values\n",
        "            loss_dict['regress'] = criterion(out['regress'], m.unsqueeze(-1))\n",
        "            loss += loss_dict['regress']\n",
        "\n",
        "\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(val_loader)\n",
        "    print(f\"Epoch {epoch} - Average Validation Loss: {average_val_loss:.4f}\")\n",
        "    print(\"Val acc\",true_preds/num_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fyK88cCa9DB",
        "outputId": "1fdebad7-9894-46d9-bad5-c33a4e5e1a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out tensor([0.2099], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3428], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.3626], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4797], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5159], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4986], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3295], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.5466], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3415], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4440], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4111], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.6373], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.3659], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3432], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4865], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4819], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4449], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4417], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3629], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3172], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5870], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.6266], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.6374], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4145], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3885], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5607], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5852], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5065], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.7167], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.3244], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4162], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4849], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4690], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4938], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5396], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5752], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.7121], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.2292], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5869], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4189], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.6360], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4066], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4879], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.2943], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.5253], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4756], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4625], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4940], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4570], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.6248], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.6810], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5113], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4595], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5081], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4425], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4850], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5247], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.6021], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.6802], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4825], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.7854], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4780], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5389], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4262], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5023], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5891], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4596], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4886], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.6906], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5458], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.2573], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.2457], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3783], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.3621], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4779], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5488], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.6052], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4697], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4872], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4061], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.4718], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.1974], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4547], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.7654], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.3136], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4688], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.2927], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5519], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5225], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3646], device='cuda:0') batch_yclass "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9 - Validation:  50%|█████     | 1/2 [01:07<01:07, 67.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, device='cuda:0')\n",
            "out tensor([0.5922], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3572], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5567], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4533], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5249], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.6550], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3896], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.2571], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4407], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.5034], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4434], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4782], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4396], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4336], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4982], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4075], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4565], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4531], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.2445], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5247], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4479], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3591], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5291], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.3986], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5099], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4556], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.6778], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4288], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.1195], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5456], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.6261], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.3143], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.7205], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3860], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.2359], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4028], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.6365], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3557], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4867], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4136], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4597], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3939], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4382], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5448], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.6679], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3169], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4756], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3616], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4812], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5993], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4625], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5551], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4807], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.6193], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4855], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3568], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4061], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.6492], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.6768], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.5058], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.3004], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5150], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.2658], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4473], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5688], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4820], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.1284], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.2824], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4210], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4606], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5949], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3566], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.5010], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4303], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.2132], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3479], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4855], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.3585], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5120], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4257], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4200], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.2643], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.3648], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5793], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.1924], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4475], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5177], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.6723], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.5758], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4713], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5188], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4884], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5096], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.5854], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5673], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5519], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.3475], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.3924], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.5681], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4089], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.5509], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4314], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.9731], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5969], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4373], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.5475], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.3123], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.6276], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4423], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.6198], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.3663], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.5362], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4991], device='cuda:0') batch_yclass "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Validation: 100%|██████████| 2/2 [02:25<00:00, 72.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9, device='cuda:0')\n",
            "out tensor([0.5443], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3171], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.6726], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.5884], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.4821], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4670], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3721], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.5609], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.3452], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.5683], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.6354], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4539], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3908], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.4073], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.3691], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3738], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4931], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4684], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.3183], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.6009], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.4862], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4873], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3948], device='cuda:0') batch_yclass tensor(9, device='cuda:0')\n",
            "out tensor([0.4286], device='cuda:0') batch_yclass tensor(1, device='cuda:0')\n",
            "out tensor([0.6527], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4834], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4664], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3394], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4955], device='cuda:0') batch_yclass tensor(0, device='cuda:0')\n",
            "out tensor([0.4289], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.3753], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3539], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.2940], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5623], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.3719], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.5443], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4339], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.5330], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "out tensor([0.5035], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3286], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.3660], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.6277], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.4800], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.2832], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.3377], device='cuda:0') batch_yclass tensor(3, device='cuda:0')\n",
            "out tensor([0.4586], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.4312], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.4952], device='cuda:0') batch_yclass tensor(8, device='cuda:0')\n",
            "out tensor([0.3008], device='cuda:0') batch_yclass tensor(4, device='cuda:0')\n",
            "out tensor([0.6101], device='cuda:0') batch_yclass tensor(6, device='cuda:0')\n",
            "out tensor([0.3966], device='cuda:0') batch_yclass tensor(2, device='cuda:0')\n",
            "out tensor([0.5282], device='cuda:0') batch_yclass tensor(7, device='cuda:0')\n",
            "out tensor([0.5087], device='cuda:0') batch_yclass tensor(5, device='cuda:0')\n",
            "Epoch 9 - Average Validation Loss: 15605.7754\n",
            "Val acc 0.09375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c8cd2bf66b4348f9b4646b24ef2cb5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8c55b8c5bac41228a5786b323c48691",
              "IPY_MODEL_28b946be94f74e1f928de2caa4d0711c",
              "IPY_MODEL_5cccd86c4af84044a82fe2293ec7b19c"
            ],
            "layout": "IPY_MODEL_5a21ad99f688433eb4d3abcd344ed6b2"
          }
        },
        "a8c55b8c5bac41228a5786b323c48691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24dba89fb6ff4e79bed81b14e78e2f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_92990433ccd94541b5f455a35a2de8db",
            "value": "100%"
          }
        },
        "28b946be94f74e1f928de2caa4d0711c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c9fc174f04440cb90758d0a87f4db4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4607c425a303422fad287ddf978ee3dd",
            "value": 3
          }
        },
        "5cccd86c4af84044a82fe2293ec7b19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb4379ad1aa4542a18bb2f78556f130",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2d9d7c5ec94bcdbcdcace2b832e1ba",
            "value": " 3/3 [00:02&lt;00:00,  1.28s/it]"
          }
        },
        "5a21ad99f688433eb4d3abcd344ed6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24dba89fb6ff4e79bed81b14e78e2f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92990433ccd94541b5f455a35a2de8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c9fc174f04440cb90758d0a87f4db4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4607c425a303422fad287ddf978ee3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acb4379ad1aa4542a18bb2f78556f130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2d9d7c5ec94bcdbcdcace2b832e1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}