{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGD056MWOjpyQe/15LrSGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShounakDas101/AIML_Hari/blob/main/Softmax_CERN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKN2SuEZe-Oc",
        "outputId": "2a0f2880-c861-433b-9864-d3110b8e8516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import h5py\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v5VnyjVfgp8",
        "outputId": "87acc154-ec41-4dc7-cced-b8ecc269d58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to the file in your Google Drive\n",
        "file_path = '/content/drive/MyDrive/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/CHECKPOINTS'\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"The file '{file_path}' exists.\")\n",
        "else:\n",
        "    print(f\"The file '{file_path}' does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi1cDEkAfXcl",
        "outputId": "0be3eb9e-8885-4e8a-db55-56e47ef42283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file '/content/drive/MyDrive/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5' exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clearing cuda cache memory\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57FuWRdLf3ox",
        "outputId": "dec8b3d3-7e6a-44eb-cb64-9ca774adf6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def find_keys(hdf5_obj, path='/'):\n",
        "    \"\"\"Recursively find keys in an HDF5 file.\"\"\"\n",
        "    keys = []\n",
        "    for key in hdf5_obj[path].keys():\n",
        "        full_path = f\"{path}/{key}\"\n",
        "        keys.append(full_path)\n",
        "        if isinstance(hdf5_obj[full_path], h5py.Group):\n",
        "            keys.extend(find_keys(hdf5_obj, full_path))\n",
        "    return keys\n",
        "\n",
        "# Open the HDF5 file\n",
        "file_path = '/content/drive/MyDrive/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'  # Replace with your actual file path\n",
        "with h5py.File(file_path, 'r') as hdf5_file:\n",
        "    # Find keys starting from the root\n",
        "    all_keys = find_keys(hdf5_file)\n",
        "\n",
        "# Print the found keys\n",
        "for key in all_keys:\n",
        "    print(key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L33AlN0f7-7",
        "outputId": "1e81f904-f9bf-4d95-e462-ad907e8acdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//X\n",
            "//y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "\n",
        "# importing electron dataset and seperating images and labels\n",
        "electron_dataset = h5py.File(\"/content/drive/MyDrive/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
        "electron_imgs=np.array(electron_dataset[\"X\"])\n",
        "electron_labels=np.array(electron_dataset[\"y\"],dtype=np.int64)\n",
        "\n",
        "# importing photon dataset and seperating images and labels\n",
        "photon_dataset = h5py.File(\"/content/drive/MyDrive/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
        "photon_imgs=np.array(photon_dataset[\"X\"])\n",
        "photon_labels=np.array(photon_dataset[\"y\"],dtype=np.int64)"
      ],
      "metadata": {
        "id": "Ip77ZBVwgErb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(electron_imgs.shape)\n",
        "print(electron_labels)"
      ],
      "metadata": {
        "id": "Mpu7qIcggKdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443339e1-9a43-4079-b498-8e64be3d1de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(249000, 32, 32, 2)\n",
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(electron_imgs.shape)\n",
        "for electron_imgs1 in electron_imgs[:1]:\n",
        "  # Display the first image from electron_imgs\n",
        "  plt.imshow(electron_imgs1[:, :, 0])  # Assuming it's a 2-channel image; adjust if needed\n",
        "  plt.title('Electron Image ch1')\n",
        "  plt.show()\n",
        "\n",
        "  # Display the first image from photon_imgs\n",
        "  plt.imshow(electron_imgs1[:, :, 1])  # Assuming it's a 2-channel image; adjust if needed\n",
        "  plt.title('Electron Image ch2')\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "QLSPO-Dtgdqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "2290167e-ffd0-410b-d42f-06100a6c7a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(249000, 32, 32, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(electron_imgs.shape)\n",
        "for photon_imgs1 in photon_imgs[:1]:\n",
        "  # Display the first image from electron_imgs\n",
        "  plt.imshow(photon_imgs1[:, :, 0])  # Assuming it's a 2-channel image; adjust if needed\n",
        "  plt.title('Electron Image ch1')\n",
        "  plt.show()\n",
        "\n",
        "  # Display the first image from photon_imgs\n",
        "  plt.imshow(photon_imgs1[:, :, 1])  # Assuming it's a 2-channel image; adjust if needed\n",
        "  plt.title('Electron Image ch2')\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "6QCMTwpCad_d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "68b2f67d-d11d-41ea-f59d-d1a4ca34fb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(249000, 32, 32, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate electron and photon images/labels\n",
        "img_arrs = torch.Tensor(np.vstack((photon_imgs,electron_imgs)))\n",
        "labels = torch.Tensor(np.hstack((photon_labels,electron_labels))).to(torch.int64)\n",
        "img_arrs = img_arrs.permute(0,3,1,2)\n",
        "print(img_arrs.shape)"
      ],
      "metadata": {
        "id": "dcwmnQ0Cgnbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfffd21-247e-4343-94ab-427cfc1a6dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([498000, 2, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del electron_imgs,photon_imgs,electron_labels,photon_labels"
      ],
      "metadata": {
        "id": "fQSecL0TkC1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {'image': self.data[idx], 'label': self.labels[idx]}\n",
        "        return sample"
      ],
      "metadata": {
        "id": "fUl2ZnnZkkYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming img_arrs and labels are already defined\n",
        "custom_dataset = CustomDataset(img_arrs, labels)\n",
        "\n",
        "# Split the dataset into training, validation, and test sets\n",
        "train_size = int(0.7 * len(custom_dataset))\n",
        "valid_size = int(0.2 * len(custom_dataset))\n",
        "test_size = len(custom_dataset) - train_size - valid_size\n",
        "train_dataset, valid_dataset, test_dataset = random_split(custom_dataset, [train_size, valid_size, test_size])\n",
        "print(len(valid_dataset)+len(test_dataset)+len(train_dataset))"
      ],
      "metadata": {
        "id": "KWyyCrCtlfy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0033ed3-734c-4d63-f01d-b063cafb0df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "498000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training, validation, and test sets\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "ch-hCbwdmULp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs = next(iter(train_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs['image'].shape, \"\\n\")\n",
        "print(\"Full\",data_inputs)"
      ],
      "metadata": {
        "id": "XwhYEd1JmbxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005bba04-be39-4463-c9f4-9bfec4cabeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inputs torch.Size([64, 2, 32, 32]) \n",
            "\n",
            "Full {'image': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), 'label': tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
            "        0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_conv1 = nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, padding=1)\n",
        "output=my_conv1((data_inputs['image']))\n",
        "print(output.shape)\n",
        "relu = nn.ReLU()\n",
        "output=output.view(batch_size,-1)\n",
        "print(output.shape[0],output.shape[1])\n",
        "fc = nn.Linear(output.shape[1],2)\n",
        "fc(output)"
      ],
      "metadata": {
        "id": "mMKDiN9bo2ar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8dc51192-e1bf-4703-80d1-57dcc5550c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ac083f90c335>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 2, 3, 3], expected input[64, 32, 32, 2] to have 2 channels, but got 32 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes (electrons and photons)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    print(epoch, end=\"\\n\")\n",
        "    for inputs in train_loader:\n",
        "        if inputs['image'].shape[0] < 64:\n",
        "            print(\"false\")\n",
        "            break\n",
        "        inputs['image'] = inputs['image'].to(device)\n",
        "        inputs['label'] = inputs['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs['image'])\n",
        "        loss = criterion(outputs, inputs['label'].long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs in test_loader:\n",
        "            inputs['image'] = inputs['image'].to(device)\n",
        "            inputs['label'] = inputs['label'].to(device)\n",
        "            outputs = model(inputs['image'])\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += inputs['label'].size(0)\n",
        "            correct += (predicted == inputs['label']).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "uGERq3CQpdWH",
        "outputId": "dd41f2da-9e10-4172-c23a-e5b4b1614abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "false\n",
            "Epoch 1/10 - Test Accuracy: 68.46%\n",
            "1\n",
            "false\n",
            "Epoch 2/10 - Test Accuracy: 70.67%\n",
            "2\n",
            "false\n",
            "Epoch 3/10 - Test Accuracy: 70.12%\n",
            "3\n",
            "false\n",
            "Epoch 4/10 - Test Accuracy: 71.64%\n",
            "4\n",
            "false\n",
            "Epoch 5/10 - Test Accuracy: 71.94%\n",
            "5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8d1ff3b0ef52>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8 * 8)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fcshoun = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relushoun = nn.ReLU()\n",
        "        self.dropoutshoun = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes (electrons and photons)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fcshoun(x)\n",
        "        x = self.relushoun(x)\n",
        "        x = self.dropoutshoun(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    # print(epoch, end=\"\\n\")\n",
        "    for inputs in train_loader:\n",
        "        if inputs['image'].shape[0] < 64:\n",
        "            # print(\"false\")\n",
        "            break\n",
        "        inputs['image'] = inputs['image'].to(device)\n",
        "        inputs['label'] = inputs['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs['image'])\n",
        "        loss = criterion(outputs, inputs['label'].long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in test_loader:\n",
        "            inputs['image'] = inputs['image'].to(device)\n",
        "            inputs['label'] = inputs['label'].to(device)\n",
        "            outputs = model(inputs['image'])\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += inputs['label'].size(0)\n",
        "            correct += (predicted == inputs['label']).sum().item()\n",
        "\n",
        "            # Calculate ROC-AUC\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            all_labels.extend(inputs['label'].cpu().numpy())\n",
        "            all_probs.extend(probs[:, 1].cpu().numpy())  # Assuming class 1 is the positive class\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Calculate ROC-AUC\n",
        "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - ROC AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ew-8L93YzJ7",
        "outputId": "8b9b22ff-40f6-44ee-e967-dd56cb5f370e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Test Accuracy: 68.58%\n",
            "Epoch 1/20 - ROC AUC: 0.7409\n",
            "Epoch 2/20 - Test Accuracy: 70.18%\n",
            "Epoch 2/20 - ROC AUC: 0.7631\n",
            "Epoch 3/20 - Test Accuracy: 71.09%\n",
            "Epoch 3/20 - ROC AUC: 0.7721\n",
            "Epoch 4/20 - Test Accuracy: 71.13%\n",
            "Epoch 4/20 - ROC AUC: 0.7744\n",
            "Epoch 5/20 - Test Accuracy: 71.80%\n",
            "Epoch 5/20 - ROC AUC: 0.7806\n",
            "Epoch 6/20 - Test Accuracy: 71.74%\n",
            "Epoch 6/20 - ROC AUC: 0.7822\n",
            "Epoch 7/20 - Test Accuracy: 70.92%\n",
            "Epoch 7/20 - ROC AUC: 0.7781\n",
            "Epoch 8/20 - Test Accuracy: 71.36%\n",
            "Epoch 8/20 - ROC AUC: 0.7828\n",
            "Epoch 9/20 - Test Accuracy: 71.91%\n",
            "Epoch 9/20 - ROC AUC: 0.7850\n",
            "Epoch 10/20 - Test Accuracy: 72.29%\n",
            "Epoch 10/20 - ROC AUC: 0.7865\n",
            "Epoch 11/20 - Test Accuracy: 72.07%\n",
            "Epoch 11/20 - ROC AUC: 0.7875\n",
            "Epoch 12/20 - Test Accuracy: 72.18%\n",
            "Epoch 12/20 - ROC AUC: 0.7898\n",
            "Epoch 13/20 - Test Accuracy: 72.59%\n",
            "Epoch 13/20 - ROC AUC: 0.7918\n",
            "Epoch 14/20 - Test Accuracy: 72.30%\n",
            "Epoch 14/20 - ROC AUC: 0.7923\n",
            "Epoch 15/20 - Test Accuracy: 72.55%\n",
            "Epoch 15/20 - ROC AUC: 0.7909\n",
            "Epoch 16/20 - Test Accuracy: 72.58%\n",
            "Epoch 16/20 - ROC AUC: 0.7914\n",
            "Epoch 17/20 - Test Accuracy: 72.12%\n",
            "Epoch 17/20 - ROC AUC: 0.7877\n",
            "Epoch 18/20 - Test Accuracy: 72.82%\n",
            "Epoch 18/20 - ROC AUC: 0.7936\n",
            "Epoch 19/20 - Test Accuracy: 72.88%\n",
            "Epoch 19/20 - ROC AUC: 0.7935\n",
            "Epoch 20/20 - Test Accuracy: 72.84%\n",
            "Epoch 20/20 - ROC AUC: 0.7942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8 * 8)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fcshoun = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relushoun = nn.ReLU()\n",
        "        self.dropoutshoun = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes (electrons and photons)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fcshoun(x)\n",
        "        x = self.relushoun(x)\n",
        "        x = self.dropoutshoun(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    # print(epoch, end=\"\\n\")\n",
        "    for inputs in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\"):\n",
        "        if inputs['image'].shape[0] < 64:\n",
        "            # print(\"false\")\n",
        "            break\n",
        "        inputs['image'] = inputs['image'].to(device)\n",
        "        inputs['label'] = inputs['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs['image'])\n",
        "        loss = criterion(outputs, inputs['label'].long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Testing\"):\n",
        "            inputs['image'] = inputs['image'].to(device)\n",
        "            inputs['label'] = inputs['label'].to(device)\n",
        "            outputs = model(inputs['image'])\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += inputs['label'].size(0)\n",
        "            correct += (predicted == inputs['label']).sum().item()\n",
        "\n",
        "            # Calculate ROC-AUC\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            all_labels.extend(inputs['label'].cpu().numpy())\n",
        "            all_probs.extend(probs[:, 1].cpu().numpy())  # Assuming class 1 is the positive class\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Calculate ROC-AUC\n",
        "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - ROC AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ-XzYhNkTH-",
        "outputId": "7023c1c5-ed1c-4cf3-e558-5b5614f26b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|| 5446/5447 [00:49<00:00, 110.75it/s]\n",
            "Epoch 1/30 - Testing: 100%|| 779/779 [00:01<00:00, 410.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Test Accuracy: 67.39%\n",
            "Epoch 1/30 - ROC AUC: 0.7413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|| 5446/5447 [00:50<00:00, 107.01it/s]\n",
            "Epoch 2/30 - Testing: 100%|| 779/779 [00:01<00:00, 426.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Test Accuracy: 70.09%\n",
            "Epoch 2/30 - ROC AUC: 0.7628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|| 5446/5447 [00:48<00:00, 111.78it/s]\n",
            "Epoch 3/30 - Testing: 100%|| 779/779 [00:02<00:00, 354.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Test Accuracy: 71.09%\n",
            "Epoch 3/30 - ROC AUC: 0.7723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|| 5446/5447 [00:48<00:00, 111.82it/s]\n",
            "Epoch 4/30 - Testing: 100%|| 779/779 [00:02<00:00, 349.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Test Accuracy: 71.56%\n",
            "Epoch 4/30 - ROC AUC: 0.7791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.46it/s]\n",
            "Epoch 5/30 - Testing: 100%|| 779/779 [00:01<00:00, 424.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Test Accuracy: 71.54%\n",
            "Epoch 5/30 - ROC AUC: 0.7818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.55it/s]\n",
            "Epoch 6/30 - Testing: 100%|| 779/779 [00:01<00:00, 426.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Test Accuracy: 71.86%\n",
            "Epoch 6/30 - ROC AUC: 0.7845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.58it/s]\n",
            "Epoch 7/30 - Testing: 100%|| 779/779 [00:01<00:00, 423.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Test Accuracy: 71.93%\n",
            "Epoch 7/30 - ROC AUC: 0.7859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|| 5446/5447 [00:48<00:00, 111.63it/s]\n",
            "Epoch 8/30 - Testing: 100%|| 779/779 [00:01<00:00, 419.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Test Accuracy: 72.01%\n",
            "Epoch 8/30 - ROC AUC: 0.7857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.66it/s]\n",
            "Epoch 9/30 - Testing: 100%|| 779/779 [00:02<00:00, 372.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Test Accuracy: 72.41%\n",
            "Epoch 9/30 - ROC AUC: 0.7906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|| 5446/5447 [00:48<00:00, 111.89it/s]\n",
            "Epoch 10/30 - Testing: 100%|| 779/779 [00:02<00:00, 306.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Test Accuracy: 72.76%\n",
            "Epoch 10/30 - ROC AUC: 0.7922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.37it/s]\n",
            "Epoch 11/30 - Testing: 100%|| 779/779 [00:02<00:00, 344.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Test Accuracy: 72.73%\n",
            "Epoch 11/30 - ROC AUC: 0.7924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.70it/s]\n",
            "Epoch 12/30 - Testing: 100%|| 779/779 [00:01<00:00, 423.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Test Accuracy: 72.73%\n",
            "Epoch 12/30 - ROC AUC: 0.7932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.87it/s]\n",
            "Epoch 13/30 - Testing: 100%|| 779/779 [00:01<00:00, 427.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Test Accuracy: 72.63%\n",
            "Epoch 13/30 - ROC AUC: 0.7940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.22it/s]\n",
            "Epoch 14/30 - Testing: 100%|| 779/779 [00:01<00:00, 427.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Test Accuracy: 72.30%\n",
            "Epoch 14/30 - ROC AUC: 0.7940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training: 100%|| 5446/5447 [00:49<00:00, 110.25it/s]\n",
            "Epoch 15/30 - Testing: 100%|| 779/779 [00:02<00:00, 356.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Test Accuracy: 72.94%\n",
            "Epoch 15/30 - ROC AUC: 0.7951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.98it/s]\n",
            "Epoch 16/30 - Testing: 100%|| 779/779 [00:02<00:00, 351.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Test Accuracy: 72.88%\n",
            "Epoch 16/30 - ROC AUC: 0.7954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.80it/s]\n",
            "Epoch 17/30 - Testing: 100%|| 779/779 [00:01<00:00, 425.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Test Accuracy: 72.70%\n",
            "Epoch 17/30 - ROC AUC: 0.7944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.10it/s]\n",
            "Epoch 18/30 - Testing: 100%|| 779/779 [00:01<00:00, 425.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Test Accuracy: 72.99%\n",
            "Epoch 18/30 - ROC AUC: 0.7957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.36it/s]\n",
            "Epoch 19/30 - Testing: 100%|| 779/779 [00:01<00:00, 424.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Test Accuracy: 72.88%\n",
            "Epoch 19/30 - ROC AUC: 0.7958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.82it/s]\n",
            "Epoch 20/30 - Testing: 100%|| 779/779 [00:02<00:00, 378.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Test Accuracy: 72.88%\n",
            "Epoch 20/30 - ROC AUC: 0.7954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.05it/s]\n",
            "Epoch 21/30 - Testing: 100%|| 779/779 [00:02<00:00, 350.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Test Accuracy: 73.02%\n",
            "Epoch 21/30 - ROC AUC: 0.7963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.71it/s]\n",
            "Epoch 22/30 - Testing: 100%|| 779/779 [00:01<00:00, 396.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Test Accuracy: 73.03%\n",
            "Epoch 22/30 - ROC AUC: 0.7963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.92it/s]\n",
            "Epoch 23/30 - Testing: 100%|| 779/779 [00:01<00:00, 422.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Test Accuracy: 72.95%\n",
            "Epoch 23/30 - ROC AUC: 0.7962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.83it/s]\n",
            "Epoch 24/30 - Testing: 100%|| 779/779 [00:01<00:00, 426.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Test Accuracy: 72.23%\n",
            "Epoch 24/30 - ROC AUC: 0.7862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.20it/s]\n",
            "Epoch 25/30 - Testing: 100%|| 779/779 [00:01<00:00, 427.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Test Accuracy: 72.99%\n",
            "Epoch 25/30 - ROC AUC: 0.7965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.01it/s]\n",
            "Epoch 26/30 - Testing: 100%|| 779/779 [00:02<00:00, 357.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Test Accuracy: 72.41%\n",
            "Epoch 26/30 - ROC AUC: 0.7952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30 - Training: 100%|| 5446/5447 [00:48<00:00, 113.03it/s]\n",
            "Epoch 27/30 - Testing: 100%|| 779/779 [00:02<00:00, 350.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Test Accuracy: 73.02%\n",
            "Epoch 27/30 - ROC AUC: 0.7964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.98it/s]\n",
            "Epoch 28/30 - Testing: 100%|| 779/779 [00:01<00:00, 417.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Test Accuracy: 72.76%\n",
            "Epoch 28/30 - ROC AUC: 0.7953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.65it/s]\n",
            "Epoch 29/30 - Testing: 100%|| 779/779 [00:01<00:00, 416.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Test Accuracy: 72.81%\n",
            "Epoch 29/30 - ROC AUC: 0.7945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30 - Training: 100%|| 5446/5447 [00:48<00:00, 112.95it/s]\n",
            "Epoch 30/30 - Testing: 100%|| 779/779 [00:01<00:00, 420.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Test Accuracy: 72.97%\n",
            "Epoch 30/30 - ROC AUC: 0.7960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 64 * 8 * 8)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fcshoun = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relushoun = nn.ReLU()\n",
        "        self.dropoutshoun = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes (electrons and photons)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fcshoun(x)\n",
        "        x = self.relushoun(x)\n",
        "        x = self.dropoutshoun(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNNModel()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.005)\n",
        "# Training the model\n",
        "num_epochs = 30\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    for inputs in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\"):\n",
        "        if inputs['image'].shape[0] < 64:\n",
        "            break\n",
        "        inputs['image'] = inputs['image'].to(device)\n",
        "        inputs['label'] = inputs['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs['image'])\n",
        "        loss = criterion(outputs, inputs['label'].long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    scheduler.step()\n",
        "    # Print average training loss for the epoch\n",
        "    average_loss = total_loss / num_batches\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Training Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Testing\"):\n",
        "            inputs['image'] = inputs['image'].to(device)\n",
        "            inputs['label'] = inputs['label'].to(device)\n",
        "            outputs = model(inputs['image'])\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += inputs['label'].size(0)\n",
        "            correct += (predicted == inputs['label']).sum().item()\n",
        "\n",
        "            # Calculate ROC-AUC\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            all_labels.extend(inputs['label'].cpu().numpy())\n",
        "            all_probs.extend(probs[:, 1].cpu().numpy())  # Assuming class 1 is the positive class\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Calculate ROC-AUC\n",
        "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs} - ROC AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f3qJbLwoqolG",
        "outputId": "f6ca3a9e-3b87-4115-9ef1-672d79a9dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.72it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Average Training Loss: 0.6388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Testing: 100%|| 779/779 [00:01<00:00, 427.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Test Accuracy: 69.15%\n",
            "Epoch 1/30 - ROC AUC: 0.7459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|| 5446/5447 [00:56<00:00, 96.81it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Average Training Loss: 0.5949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Testing: 100%|| 779/779 [00:01<00:00, 420.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Test Accuracy: 70.67%\n",
            "Epoch 2/30 - ROC AUC: 0.7683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.82it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Average Training Loss: 0.5824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Testing: 100%|| 779/779 [00:02<00:00, 359.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Test Accuracy: 71.31%\n",
            "Epoch 3/30 - ROC AUC: 0.7739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.32it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Average Training Loss: 0.5762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Testing: 100%|| 779/779 [00:01<00:00, 419.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Test Accuracy: 71.52%\n",
            "Epoch 4/30 - ROC AUC: 0.7781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Average Training Loss: 0.5721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Testing: 100%|| 779/779 [00:02<00:00, 350.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Test Accuracy: 71.66%\n",
            "Epoch 5/30 - ROC AUC: 0.7823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.17it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Average Training Loss: 0.5591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Testing: 100%|| 779/779 [00:01<00:00, 424.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Test Accuracy: 72.59%\n",
            "Epoch 6/30 - ROC AUC: 0.7899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Average Training Loss: 0.5563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Testing: 100%|| 779/779 [00:01<00:00, 422.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Test Accuracy: 72.71%\n",
            "Epoch 7/30 - ROC AUC: 0.7909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|| 5446/5447 [00:55<00:00, 98.97it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Average Training Loss: 0.5553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Testing: 100%|| 779/779 [00:01<00:00, 408.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Test Accuracy: 72.74%\n",
            "Epoch 8/30 - ROC AUC: 0.7921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.46it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Average Training Loss: 0.5543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Testing: 100%|| 779/779 [00:01<00:00, 425.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Test Accuracy: 72.82%\n",
            "Epoch 9/30 - ROC AUC: 0.7927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Average Training Loss: 0.5532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Testing: 100%|| 779/779 [00:02<00:00, 354.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Test Accuracy: 72.89%\n",
            "Epoch 10/30 - ROC AUC: 0.7925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|| 5446/5447 [01:02<00:00, 87.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Average Training Loss: 0.5514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Testing: 100%|| 779/779 [00:01<00:00, 424.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Test Accuracy: 72.88%\n",
            "Epoch 11/30 - ROC AUC: 0.7936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.45it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Average Training Loss: 0.5510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Testing: 100%|| 779/779 [00:02<00:00, 373.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Test Accuracy: 72.91%\n",
            "Epoch 12/30 - ROC AUC: 0.7938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training: 100%|| 5446/5447 [00:54<00:00, 99.65it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Average Training Loss: 0.5511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Testing: 100%|| 779/779 [00:01<00:00, 425.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Test Accuracy: 72.94%\n",
            "Epoch 13/30 - ROC AUC: 0.7938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training: 100%|| 5446/5447 [00:55<00:00, 98.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Average Training Loss: 0.5510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Testing: 100%|| 779/779 [00:02<00:00, 353.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Test Accuracy: 72.93%\n",
            "Epoch 14/30 - ROC AUC: 0.7938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training: 100%|| 5446/5447 [00:58<00:00, 93.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Average Training Loss: 0.5506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Testing: 100%|| 779/779 [00:02<00:00, 373.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Test Accuracy: 72.98%\n",
            "Epoch 15/30 - ROC AUC: 0.7939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training: 100%|| 5446/5447 [00:57<00:00, 94.63it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Average Training Loss: 0.5506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Testing: 100%|| 779/779 [00:01<00:00, 420.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Test Accuracy: 72.96%\n",
            "Epoch 16/30 - ROC AUC: 0.7939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training: 100%|| 5446/5447 [00:55<00:00, 98.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Average Training Loss: 0.5509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Testing: 100%|| 779/779 [00:02<00:00, 372.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Test Accuracy: 72.96%\n",
            "Epoch 17/30 - ROC AUC: 0.7939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training: 100%|| 5446/5447 [00:55<00:00, 97.67it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Average Training Loss: 0.5508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Testing: 100%|| 779/779 [00:01<00:00, 417.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Test Accuracy: 72.97%\n",
            "Epoch 18/30 - ROC AUC: 0.7940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30 - Training:  67%|   | 3667/5447 [00:37<00:18, 98.72it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-46c3bb275fc0>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1,dropout_rate=.2):\n",
        "        super().__init__()\n",
        "        self.my_conv1 = nn.Conv2d(in_channels=2, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.Linear=nn.Linear(32*32*16,num_classes)\n",
        "    def forward(self, x):\n",
        "        x['image']=self.my_conv1(x['image'])\n",
        "        x['image']=self.relu(x['image'])\n",
        "        x['image'] = self.dropout(x['image'])\n",
        "        x['image']=x['image'].view(batch_size,-1)\n",
        "        x['image'] = self.Linear(x['image'])\n",
        "        return x['image']\n",
        "\n"
      ],
      "metadata": {
        "id": "K3t07Np7x1dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=1, dropout_rate=0.5):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(2 * 32 * 32, 1024)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(1024)  # Batch normalization after the first linear layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear2 = nn.Linear(1024, 512)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(512)  # Batch normalization after the second linear layer\n",
        "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear3 = nn.Linear(512,128)\n",
        "        self.batch_norm3 = nn.BatchNorm1d(128)  # Batch normalization after the second linear layer\n",
        "        self.dropout3 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear4 = nn.Linear(128, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x['image'] = x['image'].view(x['image'].size(0), -1)\n",
        "        x['image'] = self.linear1(x['image'])\n",
        "        x['image'] = self.batch_norm1(x['image'])  # Apply batch normalization after the first linear layer\n",
        "        x['image'] = self.relu(x['image'])\n",
        "        x['image'] = self.dropout1(x['image'])\n",
        "        x['image'] = self.linear2(x['image'])\n",
        "        x['image'] = self.batch_norm2(x['image'])  # Apply batch normalization after the second linear layer\n",
        "        x['image'] = self.dropout2(x['image'])\n",
        "        x['image'] = self.linear3(x['image'])\n",
        "        x['image'] = self.batch_norm3(x['image'])  # Apply batch normalization after the second linear layer\n",
        "        x['image'] = self.dropout3(x['image'])\n",
        "        x['image'] = self.linear4(x['image'])\n",
        "        return x['image']\n"
      ],
      "metadata": {
        "id": "rF0LWYexx3cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "   def __init__(self, num_classes=1, dropout_rate=0.001):\n",
        "       super(MyModel,self).__init__()\n",
        "       self.linear1 = nn.Linear(2 * 32 * 32, 1024)\n",
        "       self.batch_norm1 = nn.BatchNorm1d(1024)  # Batch normalization after the first linear layer\n",
        "       self.relu = nn.ReLU()\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "       self.dropout1 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear2 = nn.Linear(1024, 256)\n",
        "       self.batch_norm2 = nn.BatchNorm1d(256)  # Batch normalization after the second linear layer\n",
        "       self.dropout2 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear3 = nn.Linear(256,32)\n",
        "       self.batch_norm3 = nn.BatchNorm1d(32)  # Batch normalization after the second linear layer\n",
        "       self.dropout3 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear4 = nn.Linear(32, 16)\n",
        "       self.batch_norm4 = nn.BatchNorm1d(16)  # Batch normalization after the second linear layer\n",
        "       self.dropout4 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear5 = nn.Linear(16, 8)\n",
        "       self.batch_norm5 = nn.BatchNorm1d(8)  # Batch normalization after the second linear layer\n",
        "       self.dropout5 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear6 = nn.Linear(8, 4)\n",
        "       self.batch_norm6 = nn.BatchNorm1d(4)  # Batch normalization after the second linear layer\n",
        "       self.dropout6 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear7 = nn.Linear(4, 2)\n",
        "       self.batch_norm7 = nn.BatchNorm1d(2)  # Batch normalization after the second linear layer\n",
        "       self.dropout7 = nn.Dropout(p=dropout_rate)\n",
        "       self.linear8 = nn.Linear(2, num_classes)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x['image'] = x['image'].view(x['image'].size(0), -1)\n",
        "       x1 = self.linear1(x['image'])\n",
        "       x1 = self.batch_norm1(x1)  # Apply batch normalization after the first linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout1(x1)\n",
        "\n",
        "       x1 = self.linear2(x1)\n",
        "       x1 = self.batch_norm2(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout2(x1)\n",
        "       x1 = self.linear3(x1)\n",
        "       x1 = self.batch_norm3(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout3(x1)\n",
        "       x1 = self.linear4(x1)\n",
        "       x1 = self.batch_norm4(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout4(x1)\n",
        "       x1 = self.linear5(x1)\n",
        "       x1 = self.batch_norm5(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout5(x1)\n",
        "       x1 = self.linear6(x1)\n",
        "       x1 = self.batch_norm6(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.relu(x1)\n",
        "       x1 = self.dropout6(x1)\n",
        "\n",
        "       x1 = self.linear7(x1)\n",
        "       x1 = self.batch_norm7(x1)  # Apply batch normalization after the second linear layer\n",
        "       x1 = self.sigmoid(x1)\n",
        "       x1 = self.dropout7(x1)\n",
        "       x1 = self.linear8(x1)\n",
        "       #x1 = self.sigmoid(x1)\n",
        "       return x1\n"
      ],
      "metadata": {
        "id": "Ti3Stq-sYX5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=1, dropout_rate=0.001):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(32 * 32, 512)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear2 = nn.Linear(512, 256)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(256)\n",
        "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear3 = nn.Linear(256, 64)\n",
        "        self.batch_norm3 = nn.BatchNorm1d(64)\n",
        "        self.dropout3 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear4 = nn.Linear(64, 32)\n",
        "        self.batch_norm4 = nn.BatchNorm1d(32)\n",
        "        self.dropout4 = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        self.Linear1 = nn.Linear(32 * 32, 512)\n",
        "        self.Batch_norm1 = nn.BatchNorm1d(512)\n",
        "        self.Relu = nn.ReLU()\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "        self.Dropout1 = nn.Dropout(p=dropout_rate)\n",
        "        self.Linear2 = nn.Linear(512, 256)\n",
        "        self.Batch_norm2 = nn.BatchNorm1d(256)\n",
        "        self.Dropout2 = nn.Dropout(p=dropout_rate)\n",
        "        self.Linear3 = nn.Linear(256, 64)\n",
        "        self.Batch_norm3 = nn.BatchNorm1d(64)\n",
        "        self.Dropout3 = nn.Dropout(p=dropout_rate)\n",
        "        self.Linear4 = nn.Linear(64, 32)\n",
        "        self.Batch_norm4 = nn.BatchNorm1d(32)\n",
        "        self.Dropout4 = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "        self.linear45 = nn.Linear(64, 32)\n",
        "        self.batch_norm45 = nn.BatchNorm1d(32)\n",
        "        self.dropout45 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear5 = nn.Linear(32, 16)\n",
        "        self.batch_norm5 = nn.BatchNorm1d(16)\n",
        "        self.dropout5 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear6 = nn.Linear(16, 8)\n",
        "        self.batch_norm6 = nn.BatchNorm1d(8)\n",
        "        self.dropout6 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear7 = nn.Linear(8, 4)\n",
        "        self.batch_norm7 = nn.BatchNorm1d(4)\n",
        "        self.dropout7 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear8 = nn.Linear(4, 2)\n",
        "        self.batch_norm9 = nn.BatchNorm1d(2)\n",
        "        self.dropout9 = nn.Dropout(p=dropout_rate)\n",
        "        self.linear9 = nn.Linear(2, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = x['image'][0].view(x['image'][0].size(0), -1)\n",
        "        x1 = self.linear1(x1)\n",
        "        x1 = self.batch_norm1(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.dropout1(x1)\n",
        "        x1 = self.linear2(x1)\n",
        "        x1 = self.batch_norm2(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.dropout2(x1)\n",
        "        x1 = self.linear3(x1)\n",
        "        x1 = self.batch_norm3(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.dropout3(x1)\n",
        "        x1 = self.linear4(x1)\n",
        "        x1 = self.batch_norm4(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.dropout4(x1)\n",
        "\n",
        "\n",
        "        x2 = x['image'][1].view(x['image'][1].size(0), -1)\n",
        "        x2 = self.Linear1(x2)\n",
        "        x2 = self.Batch_norm1(x2)\n",
        "        x2 = self.Relu(x2)\n",
        "        x2 = self.Dropout1(x2)\n",
        "        x2 = self.Linear2(x2)\n",
        "        x2 = self.Batch_norm2(x2)\n",
        "        x2 = self.Relu(x2)\n",
        "        x2 = self.Dropout2(x2)\n",
        "        x2 = self.Linear3(x2)\n",
        "        x2 = self.Batch_norm3(x2)\n",
        "        x2 = self.Relu(x2)\n",
        "        x2 = self.Dropout3(x2)\n",
        "        x2 = self.Linear4(x2)\n",
        "        x2 = self.Batch_norm4(x2)\n",
        "        x2 = self.Relu(x2)\n",
        "        x2 = self.Dropout4(x2)\n",
        "\n",
        "        x3 = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "        x3 = self.linear45(x3)\n",
        "        x3 = self.batch_norm45(x3)\n",
        "        x3 = self.dropout45(x3)\n",
        "\n",
        "        x3 = self.linear7(x3)\n",
        "        x3 = self.batch_norm7(x3)\n",
        "        x3 = self.sigmoid(x3)\n",
        "        x3 = self.dropout7(x3)\n",
        "        x3 = self.linear8(x3)\n",
        "        x3 = self.batch_norm9(x3)\n",
        "        x3 = self.sigmoid(x3)\n",
        "        x3 = self.dropout9(x3)\n",
        "        x3 = self.linear9(x3)\n",
        "\n",
        "        return x3\n"
      ],
      "metadata": {
        "id": "tFP5RHuTCqGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Output layer with 2 classes (electrons and photons)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x['image'] = self.conv1(x['image'])\n",
        "        x['image'] = self.relu1(x['image'])\n",
        "        x['image'] = self.maxpool1(x['image'])\n",
        "        x['image'] = self.conv2(x['image'])\n",
        "        x['image'] = self.relu2(x['image'])\n",
        "        x['image'] = self.maxpool2(x['image'])\n",
        "        x['image'] = x['image'].view(-1, 64 * 8 * 8)\n",
        "        x['image'] = self.fc1(x['image'])\n",
        "        x['image'] = self.relu3(x['image'])\n",
        "        x['image'] = self.dropout(x['image'])\n",
        "        x['image'] = self.fc2(x['image'])\n",
        "        return x['image']"
      ],
      "metadata": {
        "id": "KEVPfalhkeul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(num_classes=1)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "7MxHh4HF0ohX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ea752a-8bb7-40a7-8a27-085b9e7e00d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            "  (dropout1): Dropout(p=0.001, inplace=False)\n",
            "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout2): Dropout(p=0.001, inplace=False)\n",
            "  (linear3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (batch_norm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout3): Dropout(p=0.001, inplace=False)\n",
            "  (linear4): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (batch_norm4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout4): Dropout(p=0.001, inplace=False)\n",
            "  (Linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (Batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Relu): ReLU()\n",
            "  (Sigmoid): Sigmoid()\n",
            "  (Dropout1): Dropout(p=0.001, inplace=False)\n",
            "  (Linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (Batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Dropout2): Dropout(p=0.001, inplace=False)\n",
            "  (Linear3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (Batch_norm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Dropout3): Dropout(p=0.001, inplace=False)\n",
            "  (Linear4): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (Batch_norm4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (Dropout4): Dropout(p=0.001, inplace=False)\n",
            "  (linear45): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (batch_norm45): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout45): Dropout(p=0.001, inplace=False)\n",
            "  (linear5): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (batch_norm5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout5): Dropout(p=0.001, inplace=False)\n",
            "  (linear6): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (batch_norm6): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout6): Dropout(p=0.001, inplace=False)\n",
            "  (linear7): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (batch_norm7): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout7): Dropout(p=0.001, inplace=False)\n",
            "  (linear8): Linear(in_features=4, out_features=2, bias=True)\n",
            "  (batch_norm9): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout9): Dropout(p=0.001, inplace=False)\n",
            "  (linear9): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i=0\n",
        "\n",
        "# for batch_idx, batch in enumerate(train_loader):\n",
        "#     # Process your batch here\n",
        "\n",
        "#     # Check if the current batch is the last one\n",
        "#     is_last_batch = batch['image'].shape[0] < batch_size\n",
        "\n",
        "#     # Print information or perform actions based on whether it's the last batch\n",
        "#     # print(f\"Batch {batch_idx + 1}, Batch Size: {len(batch)}, Is Last Batch: {is_last_batch}\")\n",
        "#     if(is_last_batch):\n",
        "#       break\n",
        "\n",
        "#     # Continue processing the batch as needed\n",
        "#     preds = model(batch)\n"
      ],
      "metadata": {
        "id": "aW8vT-yv00m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "loss_module = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, data_loader, val_loader,loss_module, num_epochs=100):\n",
        "    train_losses = []  # Changed variable name from train_loss to train_losses\n",
        "    val_losses = []\n",
        "\n",
        "\n",
        "    # Set model to train mode\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for data_inputs in data_loader:\n",
        "            # Check if the current batch is the last one\n",
        "            is_last_batch = data_inputs['image'].shape[0] < batch_size\n",
        "            if is_last_batch:\n",
        "                break\n",
        "\n",
        "\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs['image'] = data_inputs['image'].to(device)\n",
        "            data_inputs['label'] = data_inputs['label'].to(device)\n",
        "\n",
        "\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "\n",
        "\n",
        "            # Ensure that the predictions have the same data type as the labels\n",
        "            preds = preds.squeeze(dim=1).to(data_inputs['label'].float())\n",
        "\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_inputs['label'].float())\n",
        "\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "\n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            running_loss += loss.item() * batch_size  # batch_size\n",
        "\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "        #validation plase\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        true_preds, num_preds = 0., 0.\n",
        "        with torch.no_grad():\n",
        "          for data_inputs in val_loader:\n",
        "            is_last_batch = data_inputs['image'].shape[0] < batch_size\n",
        "            if is_last_batch:\n",
        "                break\n",
        "\n",
        "\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs['image'] = data_inputs['image'].to(device)\n",
        "            data_inputs['label'] = data_inputs['label'].to(device)\n",
        "\n",
        "\n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "\n",
        "\n",
        "            # Ensure that the predictions have the same data type as the labels\n",
        "            preds = preds.squeeze(dim=1).to(data_inputs['label'].float())\n",
        "\n",
        "\n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_inputs['label'].float())\n",
        "            running_loss += loss.item() * batch_size\n",
        "\n",
        "\n",
        "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "             # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_inputs['label']).sum()\n",
        "            num_preds += batch_size\n",
        "\n",
        "\n",
        "        acc = true_preds / num_preds\n",
        "        print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")\n",
        "        val_loss = running_loss / len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss {train_loss}, Validation Loss {val_loss}\")"
      ],
      "metadata": {
        "id": "ctstjyrTLMxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(mymodel, optimizer, train_loader, val_loader,num_epochs=100)"
      ],
      "metadata": {
        "id": "nM7erU0sCt95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "4e214abd-4e33-40bb-90c8-14facb865689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-0ffeb2c9d95a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-28df6ce3db43>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, data_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (64) to match target batch_size (498000)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "\n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs in data_loader:\n",
        "            is_last_batch = data_inputs['image'].shape[0] < batch_size\n",
        "            if is_last_batch:\n",
        "                break\n",
        "\n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs['image'] = data_inputs['image'].to(device)\n",
        "            data_inputs['label'] = data_inputs['label'].to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "\n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_inputs['label']).sum()\n",
        "            num_preds += batch_size\n",
        "\n",
        "\n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ],
      "metadata": {
        "id": "deDNxeYILstf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval()  # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    preds_list = []\n",
        "    target_list = []\n",
        "\n",
        "    with torch.no_grad():  # Deactivate gradients for the following code\n",
        "        for data_inputs in data_loader:\n",
        "            is_last_batch = data_inputs['image'].shape[0] < batch_size\n",
        "            if is_last_batch:\n",
        "                break\n",
        "\n",
        "            # Step 1: Move input data to device (only strictly necessary if using GPU)\n",
        "            data_inputs['image'] = data_inputs['image'].to(device)\n",
        "            data_inputs['label'] = data_inputs['label'].to(device)\n",
        "\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.sigmoid(preds)  # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long()  # Binarize predictions to 0 and 1\n",
        "\n",
        "            preds_list.extend(preds.cpu().tolist())\n",
        "            target_list.extend(data_inputs['label'].cpu().tolist())\n",
        "\n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_inputs['label']).sum().item()\n",
        "            num_preds += batch_size\n",
        "\n",
        "    auc_roc = roc_auc_score(target_list, preds_list)\n",
        "    print(\"AUC-ROC metric score: {:.4f}\".format(auc_roc))\n",
        "\n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0 * acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "k0YNQB1_2jq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model, test_loader)"
      ],
      "metadata": {
        "id": "-uPxcP6sMygg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fi9mhKVrTKKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}