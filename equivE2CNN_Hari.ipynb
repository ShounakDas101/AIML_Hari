{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShounakDas101/AIML_Hari/blob/main/equivE2CNN_Hari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28a9bc22"
      },
      "source": [
        "# Equivariant CNN\n"
      ],
      "id": "28a9bc22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4913b545",
        "outputId": "9713617e-c1f6-4ddb-ebf8-7a093ac80a86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1QMVLpqag6S9JWqzmGM_pK4C0F1eBVIfV\n",
            "From (redirected): https://drive.google.com/uc?id=1QMVLpqag6S9JWqzmGM_pK4C0F1eBVIfV&confirm=t&uuid=50369c86-3a81-4cd8-8305-3182ce2d9e87\n",
            "To: /opt/repo/GSoC-23/data/Model_I.tgz\n",
            "100%|██████████| 1.99G/1.99G [00:34<00:00, 57.3MB/s]\n",
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1rUAKLLS3p9jDaL9R9m84JVKvMcUuVsO1\n",
            "From (redirected): https://drive.google.com/uc?id=1rUAKLLS3p9jDaL9R9m84JVKvMcUuVsO1&confirm=t&uuid=b38169b4-19fb-4c45-a09b-235fb366961b\n",
            "To: /opt/repo/GSoC-23/data/Model_I_test.tgz\n",
            "100%|██████████| 340M/340M [00:09<00:00, 37.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# try:\n",
        "#     done\n",
        "# except:\n",
        "#     import os\n",
        "\n",
        "#     os.chdir(\"../../\")\n",
        "#     from utils.download import download\n",
        "#     from utils.extract import extract\n",
        "\n",
        "#     args = {\"model\": \"Model-1\"}\n",
        "#     download(args)\n",
        "#     extract(\"data/Model_I.tgz\", \"data/\")\n",
        "#     extract(\"data/Model_I_test.tgz\", \"data/\")\n",
        "#     done = True"
      ],
      "id": "4913b545"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7db64282"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from itertools import cycle\n",
        "from PIL import Image\n",
        "from sklearn.metrics import (\n",
        "    auc,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import RandomRotation, Pad, Resize, ToTensor, Compose\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "7db64282"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "492005b2"
      },
      "outputs": [],
      "source": [
        "# images are padded to have shape 129x129.\n",
        "# this allows to use odd-size filters with stride 2 when downsampling a feature map in the model\n",
        "pad = Pad((0, 0, 1, 1), fill=0)\n",
        "# to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
        "# we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
        "resize1 = Resize(387)\n",
        "resize2 = Resize(129)\n",
        "totensor = ToTensor()\n",
        "togray = transforms.Grayscale(num_output_channels=1)"
      ],
      "id": "492005b2"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dda_ATJaaC8",
        "outputId": "790d5452-b989-4565-ebaf-c0fe4e16ca21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "5dda_ATJaaC8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7df613"
      },
      "source": [
        "# Data Preparation\n"
      ],
      "id": "8b7df613"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "98c728a5"
      },
      "outputs": [],
      "source": [
        "# train_transforms = transforms.Compose([\n",
        "#     transforms.Resize(128),\n",
        "#     transforms.Grayscale(num_output_channels=1),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# test_transforms = transforms.Compose([\n",
        "#     transforms.Resize(128),\n",
        "#     transforms.Grayscale(num_output_channels=1),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(128),\n",
        "    pad,\n",
        "    resize1,\n",
        "    # RandomRotation(180, resample=Image.BILINEAR, expand=False), # this line is original\n",
        "    RandomRotation(180, interpolation=Image.BILINEAR, expand=False),\n",
        "    resize2,\n",
        "    totensor,\n",
        "    togray,\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(128),\n",
        "    pad,\n",
        "    totensor,\n",
        "    togray,\n",
        "])"
      ],
      "id": "98c728a5"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d9d9d269"
      },
      "outputs": [],
      "source": [
        "def npy_loader(path):\n",
        "    if 'axion' in path:\n",
        "        sample = np.load(path, allow_pickle=True)[0]\n",
        "    else:\n",
        "        sample = np.load(path, allow_pickle=True)\n",
        "    sample = 255 * (sample / sample.max())\n",
        "    sample = Image.fromarray(sample.astype('uint8')).convert(\"RGB\")\n",
        "    return sample\n",
        "\n",
        "\n",
        "trainset = datasets.DatasetFolder(\n",
        "    root='/content/drive/MyDrive/Model_I',\n",
        "    loader=npy_loader,\n",
        "    extensions=['.npy'],\n",
        "    transform = train_transforms\n",
        ")\n",
        "\n",
        "testset = datasets.DatasetFolder(\n",
        "    root='/content/drive/MyDrive/Model_I',\n",
        "    loader=npy_loader,\n",
        "    extensions=['.npy'],\n",
        "    transform = test_transforms\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=True)"
      ],
      "id": "d9d9d269"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dec155fb"
      },
      "outputs": [],
      "source": [
        "del(trainset)\n",
        "del(testset)"
      ],
      "id": "dec155fb"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c541bb71"
      },
      "outputs": [],
      "source": [
        "lr = 0.0001\n",
        "epochs = 30\n",
        "gamma = 0.5\n",
        "batch_size = 64\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "id": "c541bb71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "337703e9"
      },
      "source": [
        "# Model\n"
      ],
      "id": "337703e9"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-xOse2Ka76R",
        "outputId": "6d442395-8faa-45e9-86a1-14fbbb6543bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting e2cnn\n",
            "  Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/225.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from e2cnn) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.11.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn) (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (4.9.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->e2cnn) (2.1.5)\n",
            "Installing collected packages: e2cnn\n",
            "Successfully installed e2cnn-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install e2cnn"
      ],
      "id": "G-xOse2Ka76R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21c3ca05",
        "outputId": "0543ff68-c448-4131-b92c-a6d8d8c76631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1368\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))"
      ],
      "id": "21c3ca05"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b316fcd9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from e2cnn import gspaces\n",
        "from e2cnn import nn"
      ],
      "id": "b316fcd9"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8c55bfcf"
      },
      "outputs": [],
      "source": [
        "#Defining the equivariant neural network model\n",
        "class Equivariant_Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes=3, sym_group = \"Dihyderal\", N = 4):\n",
        "\n",
        "        super(Equivariant_Network, self).__init__()\n",
        "\n",
        "        # Dihyderal Equivariance\n",
        "        if sym_group == 'Dihyderal':\n",
        "            self.r2_act = gspaces.FlipRot2dOnR2(N=N)\n",
        "\n",
        "        # Circular Equivariance\n",
        "        elif sym_group == 'Circular':\n",
        "            self.r2_act = gspaces.Rot2dOnR2(N=N)\n",
        "\n",
        "\n",
        "        # the input image is a scalar field, corresponding to the trivial representation\n",
        "        in_type = nn.FieldType(self.r2_act, [self.r2_act.trivial_repr])\n",
        "\n",
        "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
        "        self.input_type = in_type\n",
        "\n",
        "        # convolution 1\n",
        "        # first specify the output type of the convolutional layer\n",
        "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 24*[self.r2_act.regular_repr])\n",
        "        self.block1 = nn.SequentialModule(\n",
        "            nn.MaskModule(in_type, 129, margin=1),\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 2\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block1.out_type\n",
        "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block2 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool1 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 3\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block2.out_type\n",
        "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 48*[self.r2_act.regular_repr])\n",
        "        self.block3 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 4\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block3.out_type\n",
        "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block4 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool2 = nn.SequentialModule(\n",
        "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
        "        )\n",
        "\n",
        "        # convolution 5\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block4.out_type\n",
        "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 96*[self.r2_act.regular_repr])\n",
        "        self.block5 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "\n",
        "        # convolution 6\n",
        "        # the old output type is the input type to the next layer\n",
        "        in_type = self.block5.out_type\n",
        "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
        "        out_type = nn.FieldType(self.r2_act, 64*[self.r2_act.regular_repr])\n",
        "        self.block6 = nn.SequentialModule(\n",
        "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, bias=False),\n",
        "            nn.InnerBatchNorm(out_type),\n",
        "            nn.ReLU(out_type, inplace=True)\n",
        "        )\n",
        "        self.pool3 = nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0)\n",
        "\n",
        "        self.gpool = nn.GroupPooling(out_type)\n",
        "\n",
        "        # number of output channels\n",
        "        c = self.gpool.out_type.size\n",
        "\n",
        "        # Fully Connected\n",
        "        self.fully_net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(43264, 64),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ELU(inplace=True),\n",
        "            torch.nn.Linear(64, n_classes),\n",
        "            # torch.nn.Linear(64, 1),\n",
        "            # torch.nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor):\n",
        "        # wrap the input tensor in a GeometricTensor\n",
        "        # (associate it with the input type)\n",
        "        x = nn.GeometricTensor(input, self.input_type)\n",
        "\n",
        "        # apply each equivariant block\n",
        "\n",
        "        # Each layer has an input and an output type\n",
        "        # A layer takes a GeometricTensor in input.\n",
        "        # This tensor needs to be associated with the same representation of the layer's input type\n",
        "        #\n",
        "        # The Layer outputs a new GeometricTensor, associated with the layer's output type.\n",
        "        # As a result, consecutive layers need to have matching input/output types\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "\n",
        "        # pool over the spatial dimensions\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # pool over the group\n",
        "        x = self.gpool(x)\n",
        "\n",
        "        # unwrap the output GeometricTensor\n",
        "        # (take the Pytorch tensor and discard the associated representation)\n",
        "        x = x.tensor\n",
        "\n",
        "        # classify with the final fully connected layers)\n",
        "        # print(x.reshape(x.shape[0], -1).size())\n",
        "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
        "\n",
        "        return x"
      ],
      "id": "8c55bfcf"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "46cfda21"
      },
      "outputs": [],
      "source": [
        "use_cuda = True # True, if use cuda\n",
        "cuda_idx = 0 # Set idx of cuda device to be used, default is 0\n",
        "data_dir = 'images_f' # Path of the data directory\n",
        "sym_group = 'Circular' # Symmetry group to be used:{'Circular', 'Dihyderal'}\n",
        "N = 4 # Order of the symmetry group\n",
        "epochs = 40 # Number of Epochs\n",
        "batch_size = 64 # Batch Size\n",
        "lr = 5e-5 # learning rate\n",
        "n_classes = 3 # Number of classes to be classified"
      ],
      "id": "46cfda21"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6609e45a"
      },
      "outputs": [],
      "source": [
        "model = Equivariant_Network(n_classes=n_classes, sym_group = sym_group, N =N).to(device)"
      ],
      "id": "6609e45a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3736fee9"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ],
      "id": "3736fee9"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f380f477"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "total_epochs = epochs\n",
        "log_interval = 100  #Intervals after which results are displayed"
      ],
      "id": "f380f477"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0601e7f",
        "outputId": "b77a403e-75e0-4dc8-a772-d316cbf5c1fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# clearing cuda cache memory\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "id": "a0601e7f"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bae53493",
        "outputId": "16c91cf1-82db-4e8f-a66b-817c6986300e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  1.1471210718154907\n",
            "Loss:  0.7106695175170898\n",
            "epoch 0 | test accuracy: 69.23011339415125\n",
            "Loss:  0.5852265357971191\n",
            "Loss:  0.5842342972755432\n",
            "epoch 1 | test accuracy: 72.0095489811578\n",
            "Loss:  0.38477885723114014\n",
            "Loss:  0.3251599669456482\n",
            "epoch 2 | test accuracy: 81.40506437036406\n",
            "Loss:  0.2874530851840973\n",
            "Loss:  0.33370092511177063\n",
            "epoch 3 | test accuracy: 71.26779776622047\n",
            "Loss:  0.24771708250045776\n",
            "Loss:  0.3316650688648224\n",
            "epoch 4 | test accuracy: 75.44547702276408\n",
            "Loss:  0.3506377935409546\n",
            "Loss:  0.2660936117172241\n",
            "epoch 5 | test accuracy: 77.47463551879956\n",
            "Loss:  0.22510041296482086\n",
            "Loss:  0.27526289224624634\n",
            "epoch 6 | test accuracy: 70.40668428681047\n",
            "Loss:  0.19785666465759277\n",
            "Loss:  0.2934950590133667\n",
            "epoch 7 | test accuracy: 75.08739022934606\n",
            "Loss:  0.3970443904399872\n",
            "Loss:  0.21057535707950592\n",
            "epoch 8 | test accuracy: 72.02660073322534\n",
            "Loss:  0.25332221388816833\n",
            "Loss:  0.3079708516597748\n",
            "epoch 9 | test accuracy: 67.69545570807401\n",
            "Loss:  0.30664128065109253\n",
            "Loss:  0.20402254164218903\n",
            "epoch 10 | test accuracy: 74.20069912183477\n",
            "Loss:  0.2762356102466583\n",
            "Loss:  0.2344825714826584\n",
            "epoch 11 | test accuracy: 70.41521016284423\n",
            "Loss:  0.1942591816186905\n",
            "Loss:  0.4371430575847626\n",
            "epoch 12 | test accuracy: 71.12285787364652\n",
            "Loss:  0.25975969433784485\n",
            "Loss:  0.2709287703037262\n",
            "epoch 13 | test accuracy: 71.25927189018671\n",
            "Loss:  0.23824991285800934\n",
            "Loss:  0.2209496945142746\n",
            "epoch 14 | test accuracy: 71.95839372495524\n",
            "Loss:  0.24195066094398499\n",
            "Loss:  0.22323541343212128\n",
            "epoch 15 | test accuracy: 64.79665785659476\n",
            "Loss:  0.19601626694202423\n",
            "Loss:  0.15695975720882416\n",
            "epoch 16 | test accuracy: 62.48614545144514\n",
            "Loss:  0.28023600578308105\n",
            "Loss:  0.21487003564834595\n",
            "epoch 17 | test accuracy: 70.10827862562878\n",
            "Loss:  0.09108781069517136\n",
            "Loss:  0.22016245126724243\n",
            "epoch 18 | test accuracy: 69.6478813198056\n",
            "Loss:  0.17300298810005188\n",
            "Loss:  0.1576404869556427\n",
            "epoch 19 | test accuracy: 70.18501150993265\n",
            "Loss:  0.3077165484428406\n",
            "Loss:  0.15274935960769653\n",
            "epoch 20 | test accuracy: 70.83297808849859\n",
            "Loss:  0.12820672988891602\n",
            "Loss:  0.31522059440612793\n",
            "epoch 21 | test accuracy: 66.17784977406428\n",
            "Loss:  0.09063253551721573\n",
            "Loss:  0.1636222004890442\n",
            "epoch 22 | test accuracy: 69.14485463381362\n",
            "Loss:  0.18108466267585754\n",
            "Loss:  0.12249184399843216\n",
            "epoch 23 | test accuracy: 67.65282632790519\n",
            "Loss:  0.13828638195991516\n",
            "Loss:  0.4049360156059265\n",
            "epoch 24 | test accuracy: 72.18859237786683\n",
            "Loss:  0.15831221640110016\n",
            "Loss:  0.12050874531269073\n",
            "epoch 25 | test accuracy: 69.25569102225253\n",
            "Loss:  0.15099146962165833\n",
            "Loss:  0.17848210036754608\n",
            "epoch 26 | test accuracy: 70.15943388183136\n",
            "Loss:  0.1227642297744751\n",
            "Loss:  0.19745397567749023\n",
            "epoch 27 | test accuracy: 70.36405490664166\n",
            "Loss:  0.22683817148208618\n",
            "Loss:  0.11585582792758942\n",
            "epoch 28 | test accuracy: 70.60277943558701\n",
            "Loss:  0.09615470468997955\n",
            "Loss:  0.15514034032821655\n",
            "epoch 29 | test accuracy: 72.45289453491345\n",
            "Loss:  0.14825613796710968\n",
            "Loss:  0.09425365924835205\n",
            "epoch 30 | test accuracy: 70.24469264216899\n",
            "Loss:  0.20876383781433105\n",
            "Loss:  0.14780128002166748\n",
            "epoch 31 | test accuracy: 72.24827351010316\n",
            "Loss:  0.22344441711902618\n",
            "Loss:  0.13291729986667633\n",
            "epoch 32 | test accuracy: 71.48947054309829\n",
            "Loss:  0.15114672482013702\n",
            "Loss:  0.3231624662876129\n",
            "epoch 33 | test accuracy: 67.79776622047915\n",
            "Loss:  0.14300483465194702\n",
            "Loss:  0.10874594748020172\n",
            "epoch 34 | test accuracy: 72.67456731179128\n",
            "Loss:  0.06788812577724457\n",
            "Loss:  0.14170053601264954\n",
            "epoch 35 | test accuracy: 70.40668428681047\n",
            "Loss:  0.061044372618198395\n",
            "Loss:  0.20796328783035278\n",
            "epoch 36 | test accuracy: 61.761445988575325\n",
            "Loss:  0.1258736401796341\n",
            "Loss:  0.14385771751403809\n",
            "epoch 37 | test accuracy: 69.57114843550175\n",
            "Loss:  0.11367087066173553\n",
            "Loss:  0.1529233306646347\n",
            "epoch 38 | test accuracy: 71.64293631170602\n",
            "Loss:  0.18191611766815186\n",
            "Loss:  0.0716019943356514\n",
            "epoch 39 | test accuracy: 72.1715406257993\n"
          ]
        }
      ],
      "source": [
        "all_train_loss = []\n",
        "all_test_loss = []\n",
        "all_train_accuracy = []\n",
        "all_test_accuracy = []\n",
        "\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(total_epochs):\n",
        "    model.train()\n",
        "    tr_loss_epoch = []\n",
        "    test_loss_epoch = []\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (x, t) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "        y = model(x)\n",
        "        y_pred = y.flatten().to(torch.float64)\n",
        "\n",
        "        _, prediction = torch.max(y.data, 1)\n",
        "        total += t.shape[0]\n",
        "        correct += (prediction == t).sum().item()\n",
        "        loss = loss_function(y, t)\n",
        "        tr_loss_epoch.append(loss.item())\n",
        "        if i % log_interval == 0:\n",
        "            print('Loss: ',loss.item())\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    all_train_loss.append(np.asarray(tr_loss_epoch))\n",
        "    all_train_accuracy.append(correct/total*100)\n",
        "\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for i, (x, t) in enumerate(test_loader):\n",
        "                x = x.to(device)\n",
        "                t = t.to(device)\n",
        "                y = model(x)\n",
        "\n",
        "                loss = loss_function(y, t)\n",
        "                test_loss_epoch.append(loss.item())\n",
        "\n",
        "                _, prediction = torch.max(y.data, 1)\n",
        "                total += t.shape[0]\n",
        "                correct += (prediction == t).sum().item()\n",
        "\n",
        "        all_test_loss.append(np.asarray(test_loss_epoch))\n",
        "        all_test_accuracy.append(correct/total*100)\n",
        "        print(\"epoch {} | test accuracy: {}\".format(epoch,correct/total*100))\n",
        "\n",
        "        test_accuracy = correct/total*100\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "all_epochs = [i for i in range (total_epochs)]\n",
        "\n",
        "all_train_loss_mean = [j.mean() for j in all_train_loss]\n",
        "all_test_loss_mean = [j.mean() for j in all_test_loss]"
      ],
      "id": "bae53493"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1183.333041,
      "end_time": "2023-02-26T18:39:54.458046",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-02-26T18:20:11.125005",
      "version": "2.4.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}